+++
# Date this page was created.
date = "2017-04-11"

# Project title.
title = "Automated Measurement of Language Outcomes for Neurodevelopmental Disorders"

# Project summary to display on homepage.
summary = "This project builds upon progress in the parent project, “Computational Characterization of Language Use in Autism Spectrum Disorder” (R01DC012033), in which we developed natural language processing (NLP) algorithms that extract automated discourse measures (ADMs), capturing a broad range of features such as impaired conversational reciprocity, perseverative speech, idiosyncratic/stereotyped word use, and other features often associated with – but not necessarily unique to – Autism Spectrum Disorders (ASDs). ADMs are distinct from, and complement, measures that are generally the domain of conventional language instruments and that focus on aspects of linguistic competence, such as verbal productivity, grammaticality, or vocabulary. We propose to optimize and evaluate the psychometric properties of our set of NLP ADMs for use in large-scale, multi-site clinical trials as meaningful outcome measures for individuals with a range of intellectual abilities and diagnoses."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "bubbles.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["deep-learning"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "headers/bubbles-wide.jpg"
caption = "My caption :smile:"

+++

Improving spoken language use (i.e., discourse skills) is a common treatment goal for children with neurodevelopmental disorders, particularly for those with difficulties in conversational reciprocity, perseverative speech, or idiosyncratic/stereotyped word use. These features are clinically meaningful, and in previous projects, we have successfully applied Natural Language Processing (NLP) methods to measure these discourse skills using natural language samples from children with Autism Spectrum Disorder (ASD). However, while NLP methods yield diagnostically relevant measures, it is not known if they can be translated into meaningful outcome measures. To take this next step, important questions must be addressed: 

> How stable and responsive are NLP discourse measures over time? How consistent are the measures across different measurement contexts and lengths? What is their validity? To what degree are measures impacted by general language or intellectual abilities? 

Lack of knowledge about these psychometric properties of NLP discourse measures is a problem because, without it, the likelihood that children’s use of spoken language can be targeted and impacted in large-scale clinical trials is remote.

The long-term goal of this project is to harness the benefits of NLP to impact functional spoken language outcomes for children with neurodevelopmental disorders. The parent project (R01DC012033: “Computational Characterization of Language Use in Autism Spectrum Disorder”) took the first steps towards this goal by developing NLP algorithms to measure discourse skills based on raw (i.e., not coded or annotated) transcripts. Our strong results indicate difficulties in conversational reciprocity as well as elevated repetitive language behaviors among children with ASD compared to children without ASD, and were not due to differences in age, IQ, or language abilities. Our objective in this project is to take the next step to evaluate the suitability of these NLP automated discourse measures (ADMs) as outcomes for individuals with a range of intellectual abilities and diagnoses. Developing NLP algorithms requires choices of pivotal parameter settings, such as word frequency dependent weights. Whereas our previous results based on between-group contrasts were insensitive to these settings, our proposed project, involving psychometric quantities such as test-retest reliability, may be sensitive to them. Our approach will focus on optimizing stability of such measures, and assessing responsiveness to change over time, consistency across sampling contexts and sample lengths, and validity. Our rationale is that discourse measures that are automated, scalable, and psychometrically-tested would enable researchers and clinicians to better design and evaluate treatments focused on improving symptoms with clear impact on everyday social functioning.